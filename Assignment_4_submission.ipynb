{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7R0alaXgslPvtD5Q1dJnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madeleine-karlsson/AI-Course-Submission/blob/main/Assignment_4_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment task: Find the best neural network model for bikesharing demand prediction\n",
        "\n",
        "Tuning the neural network models (e.g., dropout, sizing of the network), and finding the best neural network model"
      ],
      "metadata": {
        "id": "p-irrTKJmjxD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JCV0DfTmdwT"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from json import load\n",
        "from keras.models import load_model\n",
        "filepath=\"\"\n",
        "\n",
        "\n",
        "#-------------------------------------------------data preprocessing------------------------------------------------------------------\n",
        "\n",
        "# Define the URL of a CSV file containing data.\n",
        "url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise_7_Neural_networks/Exercise7BikeSharing.csv'\n",
        "\n",
        "# Read the CSV data from the specified URL into a DataFrame (assuming you have the pandas library imported as 'pd').\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Limit the DataFrame to the first 1000 rows (selecting a subset of the data).\n",
        "df = df.iloc[:1000]\n",
        "\n",
        "# Drop specific columns (instant, dteday, casual, registered) from the DataFrame.\n",
        "df = df.drop(['instant', 'dteday', 'casual', 'registered'], axis=1)\n",
        "\n",
        "# Extract the features (input variables) by dropping the 'cnt' column.\n",
        "x = df.drop(['cnt'], axis=1)\n",
        "\n",
        "# Extract the target variable ('cnt') as the variable to predict.\n",
        "y = df['cnt']\n",
        "\n",
        "# splite the train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#-------------------------------------------------network construction------------------------------------------------------------------\n",
        "\n",
        "#************************************************Here you can choose to add the dropout layer or not***************************\n",
        "\n",
        "def construct_network_model():\n",
        "  # Create a Sequential model, which is a linear stack of layers.\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add a Dense layer with 32 units, ReLU activation, and an input dimension of 12.\n",
        "  model.add(Dense(32, activation='relu', input_dim=12))\n",
        "  # # Add a Dropout layer with a dropout rate of 0.5.\n",
        "  # model.add(Dropout(0.5))\n",
        "\n",
        "  # Add another Dense layer with 64 units and ReLU activation.\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  # # Add another Dropout layer with a dropout rate of 0.5.\n",
        "  # model.add(Dropout(0.5))\n",
        "\n",
        "  ### Tuning: Add a dense layer of 128 units\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  # model.add(Dropout(0.5))\n",
        "\n",
        "  # Add a final Dense layer with 1 unit (typically used for regression tasks).\n",
        "  model.add(Dense(1))\n",
        "  return model\n",
        "\n",
        "model=construct_network_model()\n",
        "# Compile the model with the Adam optimizer, Mean Absolute Error (MAE) loss function,\n",
        "# and MAE metric to be used during training.\n",
        "model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
        "#************************************************Here you can choose to add the dropout layer or not*****************\n",
        "\n",
        "\n",
        "#-------------------------------------------------model train------------------------------------------------------------------\n",
        "#************************************************Here you can choose to use the callback function or not**************\n",
        "# Do not use the callback function\n",
        "# hist = model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=32)\n",
        "\n",
        "# use the callback function to early stop, learning rate ajusting, save the best model\n",
        "# Create an EarlyStopping callback to monitor the validation mean absolute error (val_mae).\n",
        "# It will stop training if val_mae doesn't improve for 5 consecutive epochs and restores the best weights.\n",
        "early_stop = EarlyStopping(monitor='val_mae', patience=5, restore_best_weights=True)\n",
        "\n",
        "## Tuning: testing higer patience\n",
        "#early_stop = EarlyStopping(monitor='val_mae', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Create a ReduceLROnPlateau callback to monitor val_mae.\n",
        "# It reduces the learning rate by a factor of 0.5 if val_mae doesn't improve for 3 consecutive epochs.\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_mae', factor=0.5, patience=3)\n",
        "\n",
        "## Tuning: change learning rate factor\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='val_mae', factor=0.1, patience=3)\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='val_mae', factor=0.8, patience=3)\n",
        "\n",
        "\n",
        "# Define the file path where the best model weights will be saved.\n",
        "filepath = \"weights.best.keras\"\n",
        "\n",
        "\n",
        "# Create a ModelCheckpoint callback to monitor the validation mae (val_mae).\n",
        "# The callback will save thhe model's weights only if the validation mae improves.\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# Train the model using the fit method.\n",
        "hist = model.fit(X_train, y_train, validation_split=0.2, epochs=200, batch_size=32, callbacks=[early_stop, reduce_lr,checkpoint],verbose=0)\n",
        "\n",
        "#************************************************Here you can choose to use the callback function or not*************\n",
        "\n",
        "#-------------------------------------------------model evaluation--------------------------------------------------------------------\n",
        "\n",
        "# Set the style of the plots using Seaborn.\n",
        "sns.set()\n",
        "\n",
        "# Extract the training and validation Mean Absolute Error (MAE) from the training history.\n",
        "err = hist.history['mae']\n",
        "val_err = hist.history['val_mae']\n",
        "\n",
        "# Define the number of epochs.\n",
        "epochs = range(1, len(err) + 1)\n",
        "\n",
        "# Plot the Training MAE and Validation MAE over epochs.\n",
        "plt.plot(epochs, err, '-', label='Training MAE')\n",
        "plt.plot(epochs, val_err, ':', label='Validation MAE')\n",
        "plt.title('Training and Validation MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error')\n",
        "plt.legend(loc='upper right')\n",
        "plt.plot()\n",
        "\n",
        "# Use the trained model to predict on the test data.\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2) for the predictions.\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print('--------------------------------------'+'this is result of the trained model'+\"---------------------------------------------\")\n",
        "# Print the calculated metrics.\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "#-------------------------------------------------load model and evaluation--------------------------------------------------------------------\n",
        "if not filepath ==\"\":\n",
        "  # Load a pre-trained model from the specified file path.\n",
        "  model = load_model(filepath)\n",
        "\n",
        "  # Use the loaded model to predict on the test data.\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # Calculate Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R2) for the predictions.\n",
        "  mae = mean_absolute_error(y_test, y_pred)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "  print('--------------------------------------'+'this is result of the model loaded from the local path'+\"---------------------------------------------\")\n",
        "\n",
        "  # Print the calculated metrics.\n",
        "  print(f\"Mean Absolute Error: {mae}\")\n",
        "  print(f\"Mean Squared Error: {mse}\")\n",
        "  print(f\"R-squared: {r2}\")\n",
        "\n",
        "\n",
        "  # Create a scatter plot to visualize the relationship\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.scatter(y_test, y_pred, alpha=0.5)  # Plot actual vs. predicted values\n",
        "\n",
        "  # Add labels and title\n",
        "  plt.xlabel(\"Actual Values\")\n",
        "  plt.ylabel(\"Predicted Values\")\n",
        "  plt.title(\"Actual vs. Predicted Values\")\n",
        "\n",
        "  # Add a diagonal line for reference (perfect predictions)\n",
        "  plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', lw=2)\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "# Create a Linear Regression model\n",
        "model_linear = LinearRegression()\n",
        "model_linear.fit(X_train, y_train)\n",
        "y_pred_linear = model_linear.predict(X_test)\n",
        "\n",
        "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
        "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
        "r2_linear = r2_score(y_test, y_pred_linear)\n",
        "\n",
        "print('--------------------------------------'+'this is result of the linear regression model'+\"---------------------------------------------\")\n",
        "print(f\"Mean Absolute Error of linear model: {mae_linear}\")\n",
        "print(f\"Mean Squared Error of linear model: {mse_linear}\")\n",
        "print(f\"R-squared of linear model: {r2_linear}\")\n"
      ]
    }
  ]
}