{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG9zS4iLsMQRGlnQh9Ug65",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Madeleine-karlsson/AI-Course-Submission/blob/main/Assigment_2_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data"
      ],
      "metadata": {
        "id": "zgz4XfolKS2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# The path of the dataset\n",
        "url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise_4_Text_classification/Pakistani%20Traffic%20sentiment%20Analysis.csv'\n",
        "\n",
        "# Load the data use the pandas\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Display the data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-l2ZcAI5KRdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment task"
      ],
      "metadata": {
        "id": "h62LZ434Ksud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import ConfusionMatrixDisplay as cmd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "import os\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#-*-*-*-*-*-*chose different vectorization-*-*-*-*-*-*\n",
        "\n",
        "#(1) CountVectorizer\n",
        "#vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english',min_df=20)\n",
        "\n",
        "#(2) #HashingVectorizer\n",
        "# vectorizer = HashingVectorizer(ngram_range=(1, 2), n_features=200)\n",
        "\n",
        "#(3)TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(\n",
        "   min_df=20,\n",
        "   norm='l2',\n",
        "   smooth_idf=True,\n",
        "   use_idf=True,\n",
        "   ngram_range=(1, 1),\n",
        "   stop_words='english'\n",
        "    )\n",
        "\n",
        "#-*-*-*-*-*-*chose different vectorization-*-*-*-*-*-*\n",
        "\n",
        "# split into train/test set\n",
        "x = df['Text']\n",
        "y = df['Sentiment']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# apply the vectorizers\n",
        "x_train_vectorized = vectorizer.fit_transform(x_train)\n",
        "x_test_vectorized = vectorizer.transform(x_test)\n",
        "\n",
        "# here you can try use the grid search to find the best model parameter(a example is in SVM model)\n",
        "#-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
        "#(1)LR\n",
        "#model = LogisticRegression(max_iter=1000, random_state=0)\n",
        "#param_grid = {\n",
        " #'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        " #}\n",
        "\n",
        "#(2)KNN\n",
        "#model=KNeighborsClassifier()\n",
        "#param_grid = {\n",
        "# 'n_neighbors': [3, 5, 7, 9],\n",
        "# 'weights': ['uniform', 'distance']\n",
        "# }\n",
        "\n",
        "#(3)RF\n",
        "#model = RandomForestClassifier(random_state=0)\n",
        "#param_grid = {\n",
        " #'n_estimators': [100, 200, 300],\n",
        " #'max_depth': [None, 10, 20, 30],\n",
        " #'min_samples_split': [2, 5, 10],\n",
        " #'min_samples_leaf': [1, 2, 4]\n",
        " #}\n",
        "\n",
        "#(4)XGBoost\n",
        "#model =  XGBClassifier()\n",
        "#param_grid = {\n",
        " #'learning_rate': [0.01, 0.1, 0.2],\n",
        " #'n_estimators': [100, 200, 300],\n",
        " #'max_depth': [3, 4, 5]\n",
        "#}\n",
        "\n",
        "\n",
        "#(5)SVM\n",
        "model= SVC(probability=True)\n",
        "\n",
        "# this is an example to use the grid search to find the best parameter for SVM model\n",
        "# param_grid specifies the hyperparameter grid to search over： kernel types\n",
        "# ('linear', 'rbf', 'poly') and regularization strength C values（0.1, 1, 10）.\n",
        "param_grid = {'kernel': ['linear', 'rbf', 'poly'],'C': [0.1, 1, 10]}\n",
        "\n",
        "\n",
        "#(6)Naïve Bayes models\n",
        "model=BernoulliNB()\n",
        "param_grid = {'alpha': [0.1, 0.5, 1],'force_alpha': [True,False]}\n",
        "\n",
        "#-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
        "\n",
        "#`grid_search` performs a grid search with 5-fold cross-validation and evaluates models based on accuracy.\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "#`fit` method fits the model to the training data, systematically trying out all\n",
        "# parameter combinations.\n",
        "grid_search.fit(x_train_vectorized, y_train)\n",
        "\n",
        "#`best_params` and `best_score` store the best hyperparameters and their\n",
        "# corresponding accuracy score.\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "#The `model` is updated with the best estimator found during the grid search,\n",
        "# which can be used for further analysis.\n",
        "model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "#-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
        "\n",
        "cmd.from_estimator(\n",
        "    model,\n",
        "    x_test_vectorized,\n",
        "    y_test,\n",
        "    display_labels=['Positive','Negative'],\n",
        "    cmap='Blues',\n",
        "    xticks_rotation='vertical'\n",
        "    )\n",
        "\n",
        "#calculate accuracy\n",
        "print('The accuracy of the model is: '+str(accuracy_score(y_test,model.predict(x_test_vectorized))))"
      ],
      "metadata": {
        "id": "xJrHRoe4Kv-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here you change the reviews\n",
        "text = 'Adayala road is clear'\n",
        "\n",
        "# Make a prediction for this review\n",
        "score=model.predict_proba(vectorizer.transform([text]))[0][1]\n",
        "\n",
        "if score >0.5:\n",
        "  attitude='negative'\n",
        "else:\n",
        "  attitude='positive'\n",
        "\n",
        "print('The prediction result of this review is: '+ attitude)"
      ],
      "metadata": {
        "id": "dNOns7V1LOfv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}